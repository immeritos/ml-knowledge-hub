# 机器学习基础

- 线性回归（假设、残差方差估计、R² 与调整 R²）

- 距离度量（马氏距离、汉明距离）

- 集成学习（Bagging, Boosting, Stacking, Blending）

- 超参数搜索（Grid Search vs Random Search）

- K-means 聚类（流程、收敛特点）

- DBSCAN 聚类（核心点、参数选择、优缺点）

- 离群点检测（基于密度 LOF、基于距离 k-NN）

- Apriori 算法（关联规则挖掘）

# 深度学习核心

- 激活函数（ReLU vs Sigmoid/Tanh，梯度消失问题）

- Dropout（训练/测试阶段差异、作用机制）

- Batch Size 对梯度估计的影响

- 梯度裁剪（防止梯度爆炸 vs 梯度消失的区别）

- 优化算法（AdaGrad, RMSProp）

- CNN（卷积层、全连接层作用、反卷积/转置卷积、上采样方法、FCN 特点）

- 多模态建模（文本与视频序列处理）

# 深度学习模型架构

- Vision Transformer (ViT)（扁平结构、缺乏层级特征）

- Swin Transformer（层级化改进）

- BERT（预训练任务：MLM + NSP）

- GPT（单向语言模型 vs BERT 双向）

- RoBERTa / ELECTRA（预训练任务演化）