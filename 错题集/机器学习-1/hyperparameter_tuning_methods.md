# 📑 超参数调优方法（Grid Search / Random Search / Bayesian Optimization）

## 1. Grid Search （网格搜索）
- **思想**：对超参数空间进行网格划分，逐一尝试所有组合。  
- **优点**：简单直接，能保证找到网格范围内的最优解。  
- **缺点**：计算量随维度呈指数增长（维度灾难），效率低。  
- **适用场景**：参数少（1~3个）、范围较小。  
- **例子**：SVM 的 `(C, γ)` 调参。  

---

## 2. Random Search （随机搜索）
- **思想**：在参数空间中随机采样，评估效果。  
- **优点**：比 Grid Search 更高效；在高维时，随机取样能覆盖更多有效区域。  
- **缺点**：不保证找到全局最优解。  
- **适用场景**：高维参数空间、计算预算有限时。  
- **实证结果**：同样预算下，Random Search 往往比 Grid Search 更好。  

---

## 3. Bayesian Optimization （贝叶斯优化）
- **思想**：将代价函数 `f(θ)` 视为黑箱函数：  
  1. 先采样若干点，建立代理模型（如高斯过程 GP）。  
  2. 根据代理模型，选择下一个最优点（探索 vs 利用）。  
  3. 更新代理模型，迭代优化。  
- **优点**：样本效率高，用更少的评估找到接近最优解。  
- **缺点**：实现复杂，代理模型本身有计算开销；高维时效果差。  
- **适用场景**：评估代价昂贵（如训练大模型）、参数维度中低（~10-20）。  

---

## 4. 对比总结

| 方法 | 思想 | 优点 | 缺点 | 适用场景 |
|------|------|------|------|----------|
| **Grid Search** | 穷举网格 | 简单，能找到网格内最优解 | 维度灾难，效率低 | 参数少、范围小 |
| **Random Search** | 随机采样 | 高效，覆盖更广 | 不保证最优 | 高维空间、预算有限 |
| **Bayesian Optimization** | 代理模型+智能搜索 | 样本效率高，适合昂贵评估 | 实现复杂，维度高时难用 | 评估代价大、中低维调参 |

---

## 5. 类比理解
- **Grid Search**：像“遍历菜单上所有菜，逐一品尝”。  
- **Random Search**：像“随机点几道菜，多试几次，往往能吃到好吃的”。  
- **Bayesian Optimization**：像“根据之前吃的体验，聪明地推测下次该点什么”。  
