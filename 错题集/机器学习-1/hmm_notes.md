# 📑 概率图模型（HMM 三大问题及算法）

## 1. 隐马尔可夫模型 (HMM) 基本概念
- **隐状态序列**：满足马尔科夫性，状态不可直接观测。  
- **观测序列**：由隐状态生成的可见符号。  
- **应用**：语音识别、词性标注、基因序列分析。  

---

## 2. 三个基本问题

### （1）评估问题（Evaluation）
- **任务**：已知模型参数 `λ=(A,B,π)` 和观测序列 `O`，计算 `P(O|λ)`。  
- **算法**：前向-后向 (Forward-Backward)  
  - 前向变量：`αₜ(i) = P(o₁,...,oₜ, qₜ=i | λ)`  
  - 后向变量：`βₜ(i) = P(oₜ₊₁,...,o_T | qₜ=i, λ)`  
  - 复杂度：`O(N²T)`  

### （2）解码问题（Decoding）
- **任务**：求给定观测序列的最优隐状态序列 `Q*`。  
- **算法**：维特比 (Viterbi)  
  - 递推公式：`δₜ(j) = maxᵢ [δₜ₋₁(i) aᵢⱼ] bⱼ(oₜ)`  
  - 回溯得到最优路径。  
  - 复杂度：`O(N²T)`  

### （3）学习问题（Learning）
- **任务**：已知观测序列，估计最优模型参数 `λ`。  
- **算法**：Baum-Welch (EM 算法特例)  
  - 计算期望：`γₜ(i)`, `ξₜ(i,j)` 
  - 更新转移概率与发射概率：  
    ```math
    a_{ij} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)},
    \quad
    b_j(k) = \frac{\sum_{t:o_t=v_k} \gamma_t(j)}{\sum_{t=1}^T \gamma_t(j)}
    ```
  - 迭代至收敛。  

---

## 3. 总结表

| 问题 | 任务 | 算法 | 时间复杂度 |
|------|------|------|-------------|
| **评估** | 求 $P(O\|\lambda)$ | 前向-后向 | $O(N²T)$ |
| **解码** | 求最优隐状态序列 | 维特比 | $O(N²T)$ |
| **学习** | 估计参数 $λ$ | Baum-Welch (EM) | 每次迭代 $O(N²T)$ |

---

## 4. 常见误区
- **维特比 ≠ 概率计算**：维特比求最优路径，不是求总概率。  
- **Baum-Welch ≠ 新算法**：其实就是 HMM 上的 EM 特例。  
- **前向后向 vs 维特比**：前向后向是“求和”，维特比是“取最大”。  

---

## 5. 一句话总结
- **评估问题**：算概率 → 前向后向。  
- **解码问题**：找路径 → 维特比。  
- **学习问题**：估参数 → Baum-Welch。  
