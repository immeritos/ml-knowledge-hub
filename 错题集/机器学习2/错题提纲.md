# 机器学习与深度学习错题知识点提纲

##  模型性能与误差分析

-   **偏差-方差分解**
    -   公式: 总误差 = 偏差² + 方差 + 噪声
    -   例题:
        假设一个高阶多项式模型在训练集表现很好但测试集误差很大，这说明偏差/方差哪个主导？
-   **精确率、召回率、FPR**
    -   Precision, Recall, FPR 的定义与计算
    -   例题: 二分类模型召回率 99%，FPR 1%，正负样本比 1:100，求
        Precision。
-   **Naive Bayes 的特征问题**
    -   高频词的影响 → TF-IDF/特征选择改进
    -   重复特征 / 高相关特征对 NB 的影响
    -   例题: 使用 NB
        时，不小心把某一列特征复制一份，模型效果会怎样？为什么？

------------------------------------------------------------------------

## 📌 算法与模型

-   **K-means 聚类**
    -   无监督，不利用标签
    -   与分类任务区别
    -   例题: 为什么 K-means 不能直接用于文本分类？
-   **KNN**
    -   分类：多数投票
    -   回归：邻居均值/加权均值
    -   对数据缩放敏感（需归一化/标准化）
    -   例题: 在 KNN 中，为什么特征归一化很重要？
-   **决策树 & CART**
    -   ID3/C4.5 仅支持分类
    -   CART 可做分类 & 回归
    -   例题: 哪种决策树可用于回归任务？
-   **朴素贝叶斯文本分类**
    -   公式: $P(y\|d) \propto P(y) \prod P(w\|y)$
    -   高频词问题 & 改进方法

------------------------------------------------------------------------

## 📌 深度学习模型与参数计算

-   **MLP 参数计算**
    -   Dense 层参数数 = 输入维度 × 输出单元 + 输出单元（偏置）
    -   Dropout 无参数
    -   例题: 输入 100，Dense(32) + Dense(1)，一共多少参数？
    ```python
    model = Sequential()
    model.add(Dense(32, activation='relu', input_dim=100))   # 第一层全连接
    model.add(Dropout(0.5))                                 # Dropout，不含参数
    model.add(Dense(1, activation='sigmoid'))               # 第二层全连接
    ```
-   **偏置向量大小**
    -   偏置大小 = 输出单元数
    -   例题: Dense(64) 的偏置向量有多大？

------------------------------------------------------------------------

## 📌 优化与学习问题

-   **黑盒攻击**
    -   基于梯度估计：有限差分
    -   基于优化搜索：遗传算法、进化算法
    -   例题: 如果只知道模型输入和输出，如何生成对抗样本？
-   **特征缩放敏感性**
    -   KNN、SVM 对归一化敏感
    -   树模型不敏感

------------------------------------------------------------------------

## 📌 经典理论与数学基础

-   **线性规划对偶性**
    -   弱对偶：对偶 ≤ 原问题
    -   强对偶：若两者可行，最优值相等
    -   可行性/无界性的对应关系
    -   例题: 原问题无解，对偶问题一定无解吗？
